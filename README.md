# ecommerce-price-prediction
Predicting product prices using ML models in an e-commerce setting.
ğŸŒ Price Prediction for E-Commerce Using Machine Learning
ğŸ“˜ Project Overview
This project aims to predict the prices of products in an e-commerce setting using historical product data and machine learning. By analyzing features such as product category, brand, rating, reviews, and specifications, the model estimates an appropriate selling price. This helps e-commerce platforms and sellers set competitive prices, optimize profits, and improve customer trust.

ğŸ“š Table of Contents
ğŸŒ Societal and Industrial Impact

ğŸ¯ Objectives

ğŸ” Research Questions

ğŸ§  Contributions

ğŸ“¦ Dataset

ğŸ› ï¸ Methodology

ğŸ¤– ML Models Used

â“ Why These Models?

ğŸ“ Evaluation Metrics

âš™ï¸ Hyperparameter Tuning

ğŸŒ Societal and Industrial Impact
ğŸ›’ Helps sellers set competitive and fair prices.

ğŸ’° Increases transparency in e-commerce pricing.

ğŸ“¦ Improves buyer trust through consistent pricing models.

ğŸ“Š Supports data-driven decisions in online marketplaces.

ğŸ¯ Objectives
Understand which product features influence pricing.

Train regression models to predict product prices accurately.

Evaluate model performance to choose the best one.

Offer price recommendations based on data insights.

ğŸ” Research Questions
What features affect the price of a product in e-commerce?

Why is accurate price prediction important for sellers and buyers?

How can ML models be used to predict price based on product data?

ğŸ§  Contributions
Built a machine learning pipeline to predict product prices.

Extracted and engineered features relevant to pricing.

Compared multiple models to identify the most accurate one.

Delivered insights into price influencers for strategic pricing.

ğŸ“¦ Dataset
Type: Secondary Dataset

Source: (e.g., Kaggle - E-commerce Product Prices or Flipkart/Amazon data)

Features:

Product Name

Brand

Category

Rating

Number of Reviews

Product Specifications (e.g., size, weight, RAM)

Selling Price (Target)

ğŸ› ï¸ Methodology
Data Collection (from open sources like Kaggle)

Data Cleaning & Preprocessing

Feature Engineering

Train-Test Split

Model Training (Regression models)

Evaluation & Visualization

Hyperparameter Tuning

ğŸ¤– ML Models Used
Linear Regression

Decision Tree Regressor

Random Forest Regressor

XGBoost Regressor (optional)

â“ Why These Models?
Easy to understand and implement

Effective for tabular regression tasks

Tree-based models handle non-linearity and mixed feature types

XGBoost offers high accuracy in structured datasets

ğŸ“ Evaluation Metrics
RÂ² Score

MAE (Mean Absolute Error)

RMSE (Root Mean Squared Error)

âš™ï¸ Hyperparameter Tuning
Used GridSearchCV / manual tuning for:

n_estimators, max_depth, min_samples_split (Random Forest, XGBoost)

Learning rate (for XGBoost)

Polynomial degree (if trying Polynomial Regression)

